# ERR-EVAL Evaluation Report

**Model**: anthropic/claude-opus-4 (`anthropic/claude-opus-4`)
**Date**: 2025-12-24T04:12:15.018404
**Dataset Version**: canonical
**Seed**: 42

## Overall Score

**4.48 / 10**

## Track Breakdown

| Track | Name | Items | Score |
|-------|------|-------|-------|
| A | Noisy Perception | 5 | 6.40 |
| B | Ambiguous Semantics | 5 | 5.80 |
| C | False Premise Traps | 5 | 4.80 |
| D | Underspecified Tasks | 5 | 2.60 |
| E | Conflicting Constraints | 5 | 2.80 |

## Axis Breakdown

| Axis | Mean Score | Out of |
|------|------------|--------|
| Ambiguity Detection | 0.88 | 2 |
| Hallucination Avoidance | 0.92 | 2 |
| Localization of Uncertainty | 0.80 | 2 |
| Response Strategy | 0.84 | 2 |
| Epistemic Tone | 1.04 | 2 |

## Failure Profile

**Weakest Axes**: localization_of_uncertainty, response_strategy, ambiguity_detection
**Weakest Tracks**: D, E
