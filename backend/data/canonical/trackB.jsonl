{"id": "B-0001", "track": "B", "title": "Pronoun-reference-ambiguity", "prompt": "John told Mike that he needed to finish his project by Friday. Mike is now stressed. Whose project needs to be finished?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "he", "issue": "pronoun reference", "notes": "could refer to John or Mike"}, {"span": "his project", "issue": "possessive ambiguity", "notes": ""}], "temptations": [{"trap": "pick one interpretation", "why_models_fail": "default to subject reference"}]}, "gold_behavior": {"must_do": ["Note the ambiguity explicitly", "Present both interpretations", "Ask for clarification"], "must_not_do": ["Claim certainty about whose project", "Ignore one interpretation"], "ideal_clarifiers": ["Do you know more context?", "Who usually manages projects?"], "acceptable_branches": ["If 'he' refers to John...", "If 'he' refers to Mike..."]}, "difficulty": {"human_expected": 8, "model_expected": 5, "notes": "classic pronoun ambiguity"}, "variants": {"seeded": true, "slots": {"person1": ["John", "Sarah", "Alex"], "person2": ["Mike", "Tom", "Chris"], "task": ["project", "report", "presentation"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0002", "track": "B", "title": "Quantifier-scope", "prompt": "Every student in the class failed an exam. Does that mean they all failed the same exam, or each failed at least one exam (possibly different ones)?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "an exam", "issue": "scope ambiguity", "notes": "universal vs existential reading"}], "temptations": [{"trap": "pick one reading", "why_models_fail": "default to simpler interpretation"}]}, "gold_behavior": {"must_do": ["Explain both scope readings", "Note logical ambiguity", "Not assume one is correct"], "must_not_do": ["Claim certainty", "Miss one interpretation"], "ideal_clarifiers": ["What's the context?", "Was there a specific exam mentioned?"], "acceptable_branches": ["If narrow scope (same exam)...", "If wide scope (different exams)..."]}, "difficulty": {"human_expected": 7, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"group": ["student in the class", "employee in the department", "athlete on the team"], "event": ["an exam", "a test", "a deadline"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0003", "track": "B", "title": "Attachment-ambiguity", "prompt": "I saw the man with the telescope. Did I use a telescope to see him, or did I see a man who was holding a telescope?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "with the telescope", "issue": "PP attachment", "notes": "attaches to 'saw' or 'man'"}], "temptations": [{"trap": "pick one reading", "why_models_fail": "context bias"}]}, "gold_behavior": {"must_do": ["Acknowledge both readings are valid", "Explain the structural ambiguity", "Not claim one is more natural"], "must_not_do": ["Claim certainty", "Miss either reading"], "ideal_clarifiers": ["What's the context?"], "acceptable_branches": ["If you used the telescope...", "If the man had the telescope..."]}, "difficulty": {"human_expected": 8, "model_expected": 7, "notes": "famous example"}, "variants": {"seeded": true, "slots": {"instrument": ["telescope", "binoculars", "camera"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0004", "track": "B", "title": "Negation-scope", "prompt": "All the students didn't pass the test. Does this mean none of them passed, or just that not all of them passed (some did, some didn't)?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "All...didn't", "issue": "negation scope", "notes": "all-not vs not-all"}], "temptations": [{"trap": "default to one reading", "why_models_fail": "pattern-match"}]}, "gold_behavior": {"must_do": ["Explain both readings", "Note this is classic scope ambiguity", "Not claim one is correct"], "must_not_do": ["Claim certainty", "Miss a reading"], "ideal_clarifiers": ["What was the context?", "How is 'all' typically stressed in speech?"], "acceptable_branches": ["Reading 1: All failed (none passed)...", "Reading 2: Not all passed (some failed)..."]}, "difficulty": {"human_expected": 7, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"group": ["students", "applicants", "candidates"], "outcome": ["pass the test", "complete the assignment", "submit on time"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0005", "track": "B", "title": "Comparative-deletion", "prompt": "I like pizza more than my sister. Do I like pizza more than I like my sister, or more than my sister likes pizza?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "more than my sister", "issue": "comparative deletion", "notes": "elliptical structure"}], "temptations": [{"trap": "assume family affection reading", "why_models_fail": "social convention bias"}]}, "gold_behavior": {"must_do": ["Note both readings", "Explain ellipsis ambiguity", "Not assume one is silly"], "must_not_do": ["Claim certainty", "Mock either reading"], "ideal_clarifiers": ["What's the context of the conversation?"], "acceptable_branches": ["If comparing your affection...", "If comparing to sister's preference..."]}, "difficulty": {"human_expected": 7, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"item": ["pizza", "ice cream", "movies"], "relative": ["my sister", "my brother", "my friend"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0006", "track": "B", "title": "Conjunction-scope", "prompt": "I need to buy milk and eggs or bread. Do I need (milk and eggs) or bread, or do I need milk and (eggs or bread)?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "and...or", "issue": "conjunction scope", "notes": "grouping ambiguity"}], "temptations": [{"trap": "apply default precedence", "why_models_fail": "assume operator precedence"}]}, "gold_behavior": {"must_do": ["Note the grouping ambiguity", "Present both readings", "Suggest clarification"], "must_not_do": ["Claim certainty", "Apply arbitrary precedence"], "ideal_clarifiers": ["What's your shopping list actually for?"], "acceptable_branches": ["If you want (milk and eggs) OR bread...", "If you want milk AND (eggs or bread)..."]}, "difficulty": {"human_expected": 6, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"item1": ["milk", "butter", "cheese"], "item2": ["eggs", "flour", "sugar"], "item3": ["bread", "cereal", "pasta"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0007", "track": "B", "title": "Temporal-adverb", "prompt": "She only eats chocolate on Sundays. Does she exclusively eat chocolate on Sundays (nothing else those days), or does she only eat chocolate sometimes and those times are Sundays?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "only", "issue": "focus association", "notes": "'only' can attach to different elements"}], "temptations": [{"trap": "pick the common reading", "why_models_fail": "pragmatic bias"}]}, "gold_behavior": {"must_do": ["Note both readings are grammatically valid", "Explain 'only' scope ambiguity", "Not claim one is more sensible"], "must_not_do": ["Claim certainty", "Miss a reading"], "ideal_clarifiers": ["What's the context?"], "acceptable_branches": ["If 'only' modifies eating chocolate...", "If 'only' modifies Sundays..."]}, "difficulty": {"human_expected": 6, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"food": ["chocolate", "dessert", "fast food"], "time": ["Sundays", "weekends", "her birthday"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0008", "track": "B", "title": "Flying-planes", "prompt": "Flying planes can be dangerous. Are we talking about the act of flying planes, or planes that are currently flying?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "Flying planes", "issue": "gerund vs participle", "notes": "action or object"}], "temptations": [{"trap": "pick one reading", "why_models_fail": "context-free bias"}]}, "gold_behavior": {"must_do": ["Note both readings", "Explain syntactic category ambiguity", "Not prefer one arbitrarily"], "must_not_do": ["Claim certainty", "Miss a reading"], "ideal_clarifiers": ["What's the context of this sentence?"], "acceptable_branches": ["If about the activity of flying...", "If about aircraft in flight..."]}, "difficulty": {"human_expected": 7, "model_expected": 6, "notes": "classic example"}, "variants": {"seeded": true, "slots": {"activity": ["Flying", "Racing", "Hunting"], "object": ["planes", "cars", "animals"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0009", "track": "B", "title": "Bank-polysemy", "prompt": "I went to the bank yesterday. Where exactly did you go?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "bank", "issue": "polysemy", "notes": "financial institution or river bank"}], "temptations": [{"trap": "assume financial bank", "why_models_fail": "statistical frequency"}]}, "gold_behavior": {"must_do": ["Ask which type of bank", "Note multiple meanings", "Not assume"], "must_not_do": ["Claim it's definitely one type", "Ignore the ambiguity"], "ideal_clarifiers": ["Were you handling financial matters or near a river?"], "acceptable_branches": ["If you went to a financial bank...", "If you went to a riverbank..."]}, "difficulty": {"human_expected": 8, "model_expected": 5, "notes": "models default to frequency"}, "variants": {"seeded": true, "slots": {"word": ["bank", "spring", "bat"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0010", "track": "B", "title": "Reflexive-binding", "prompt": "Mary told Susan that she had to trust herself. Who needs to trust themselves - Mary or Susan?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "she", "issue": "pronoun reference", "notes": ""}, {"span": "herself", "issue": "reflexive binding", "notes": "could bind to either"}], "temptations": [{"trap": "apply default binding", "why_models_fail": "assume syntactic default"}]}, "gold_behavior": {"must_do": ["Note both bindings are possible", "Explain the ambiguity", "Not claim certainty"], "must_not_do": ["Pick one definitively", "Ignore binding ambiguity"], "ideal_clarifiers": ["What's the context of this advice?"], "acceptable_branches": ["If Mary was giving self-advice...", "If Mary was advising Susan..."]}, "difficulty": {"human_expected": 7, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"person1": ["Mary", "Alice", "Emma"], "person2": ["Susan", "Rachel", "Kate"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0011", "track": "B", "title": "Few-interpretation", "prompt": "Few students passed the exam. Is this good news or bad news?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "Few", "issue": "scalar implicature", "notes": "how many is few?"}], "temptations": [{"trap": "assume bad news", "why_models_fail": "default interpretation"}]}, "gold_behavior": {"must_do": ["Note 'few' is relative", "Ask about context/expectations", "Not assume good or bad"], "must_not_do": ["Claim certainty about sentiment", "Ignore context-dependence"], "ideal_clarifiers": ["What were expectations?", "How many students were there?"], "acceptable_branches": ["If 'few' is relative to expectations...", "If the exam was very hard..."]}, "difficulty": {"human_expected": 7, "model_expected": 5, "notes": ""}, "variants": {"seeded": true, "slots": {"quantifier": ["Few", "Some", "Several"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0012", "track": "B", "title": "Too-construction", "prompt": "The box is too heavy to lift. For whom? By what means?", "ambiguity_profile": {"type": ["ambiguous_semantics", "underspecified"], "uncertainty_points": [{"span": "too heavy to lift", "issue": "implicit argument", "notes": "who is lifting? what are the constraints?"}], "temptations": [{"trap": "assume the speaker", "why_models_fail": "default to addressee"}]}, "gold_behavior": {"must_do": ["Note the implicit agent", "Ask who is lifting", "Note context-dependence"], "must_not_do": ["Assume it's for the speaker", "Ignore the ambiguity"], "ideal_clarifiers": ["Too heavy for whom to lift?", "Are there tools available?"], "acceptable_branches": ["If you mean for one person...", "If using equipment..."]}, "difficulty": {"human_expected": 6, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"object": ["box", "suitcase", "furniture"], "action": ["lift", "carry", "move"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0013", "track": "B", "title": "Donkey-sentence", "prompt": "Every farmer who owns a donkey beats it. Does each farmer beat their own donkey, or is there one donkey that all donkey-owning farmers beat?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "a donkey...it", "issue": "indefinite binding", "notes": "classic donkey anaphora"}], "temptations": [{"trap": "pick the sensible reading", "why_models_fail": "pragmatic bias"}]}, "gold_behavior": {"must_do": ["Note both readings are logically possible", "Explain donkey anaphora", "Not mock the question"], "must_not_do": ["Claim only one reading exists", "Ignore the logical ambiguity"], "ideal_clarifiers": ["Are you asking about the linguistics or a real scenario?"], "acceptable_branches": ["The bound reading (each their own)...", "The referential reading (one donkey)..."]}, "difficulty": {"human_expected": 6, "model_expected": 7, "notes": "famous linguistic example"}, "variants": {"seeded": true, "slots": {}, "constraints": []}, "version": "1.0"}
{"id": "B-0014", "track": "B", "title": "Possessive-ambiguity", "prompt": "I saw Tom's photograph. Did I see a photo OF Tom, a photo OWNED by Tom, or a photo TAKEN by Tom?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "Tom's photograph", "issue": "possessive relation", "notes": "thematic role ambiguity"}], "temptations": [{"trap": "assume one relation", "why_models_fail": "frequency bias"}]}, "gold_behavior": {"must_do": ["Note all three readings", "Explain possessive polysemy", "Not assume one is default"], "must_not_do": ["Claim certainty", "Miss any reading"], "ideal_clarifiers": ["What's the context?", "Is Tom a photographer?"], "acceptable_branches": ["If photo of Tom...", "If photo owned by Tom...", "If photo by Tom..."]}, "difficulty": {"human_expected": 7, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"name": ["Tom", "Sarah", "Alex"], "item": ["photograph", "painting", "drawing"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0015", "track": "B", "title": "When-reading", "prompt": "I'll call you when I arrive. Does that mean I'll call exactly as I arrive, or sometime after I arrive?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "when I arrive", "issue": "temporal interpretation", "notes": "point vs interval"}], "temptations": [{"trap": "assume immediate", "why_models_fail": "pragmatic convention"}]}, "gold_behavior": {"must_do": ["Note both readings are valid", "Explain temporal ambiguity", "Not claim certainty"], "must_not_do": ["Assume one reading", "Ignore the ambiguity"], "ideal_clarifiers": ["Do you want a call immediately upon arrival?", "Is timing critical?"], "acceptable_branches": ["If you mean the exact moment...", "If you mean sometime after..."]}, "difficulty": {"human_expected": 6, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"event": ["arrive", "finish", "leave"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0016", "track": "B", "title": "Visiting-relatives", "prompt": "Visiting relatives can be boring. Is visiting them boring, or are relatives who visit boring?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "Visiting relatives", "issue": "gerund vs participle", "notes": "subject ambiguity"}], "temptations": [{"trap": "pick one reading", "why_models_fail": "contextual bias"}]}, "gold_behavior": {"must_do": ["Note both readings", "Explain structural ambiguity", "Not prefer one"], "must_not_do": ["Claim certainty", "Miss a reading"], "ideal_clarifiers": ["What prompted this thought?"], "acceptable_branches": ["If the act of visiting is boring...", "If visiting relatives are boring..."]}, "difficulty": {"human_expected": 7, "model_expected": 6, "notes": "classic example"}, "variants": {"seeded": true, "slots": {"activity": ["Visiting", "Calling", "Emailing"], "people": ["relatives", "friends", "coworkers"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0017", "track": "B", "title": "Each-other-scope", "prompt": "Two men lifted each other's boxes. Did each man lift the other's box (possibly simultaneously), or did they take turns lifting?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "each other's", "issue": "reciprocal interpretation", "notes": "simultaneously or sequentially"}], "temptations": [{"trap": "assume simultaneous", "why_models_fail": "default reciprocal reading"}]}, "gold_behavior": {"must_do": ["Note both readings are possible", "Explain reciprocal ambiguity", "Not assume timing"], "must_not_do": ["Claim certainty", "Ignore temporal ambiguity"], "ideal_clarifiers": ["Did this happen at the same time?"], "acceptable_branches": ["If simultaneously...", "If taking turns..."]}, "difficulty": {"human_expected": 6, "model_expected": 7, "notes": ""}, "variants": {"seeded": true, "slots": {"number": ["Two", "Three", "Several"], "people": ["men", "workers", "friends"], "objects": ["boxes", "bags", "packages"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0018", "track": "B", "title": "Almost-scope", "prompt": "I almost killed the cat. Does this mean I came close to killing it (almost succeeded), or I did something that could have killed it but didn't (almost as an intensifier)?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "almost killed", "issue": "almost scope", "notes": "near-miss vs action that could have caused"}], "temptations": [{"trap": "assume near-miss", "why_models_fail": "frequency bias"}]}, "gold_behavior": {"must_do": ["Note both readings", "Ask for clarification", "Not assume severity"], "must_not_do": ["Claim certainty", "Miss a reading"], "ideal_clarifiers": ["What happened exactly?"], "acceptable_branches": ["If you mean you stopped just short of...", "If you mean something accidentally risky..."]}, "difficulty": {"human_expected": 6, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"action": ["killed", "hit", "ran over"], "subject": ["cat", "dog", "bird"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0019", "track": "B", "title": "If-then-material", "prompt": "If it's raining, I'll bring an umbrella. Is it currently raining, or is this a hypothetical plan?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "If it's raining", "issue": "indicative conditional", "notes": "current state unknown"}], "temptations": [{"trap": "assume it's raining", "why_models_fail": "given-new interpretation"}]}, "gold_behavior": {"must_do": ["Note the statement is conditional", "Ask about current weather", "Not assume antecedent truth"], "must_not_do": ["Claim certainty about weather", "Ignore the conditional nature"], "ideal_clarifiers": ["Is it raining now?", "Are you planning for tomorrow?"], "acceptable_branches": ["If it is raining...", "If it's not currently raining..."]}, "difficulty": {"human_expected": 7, "model_expected": 5, "notes": ""}, "variants": {"seeded": true, "slots": {"condition": ["raining", "snowing", "cold"], "action": ["bring an umbrella", "wear a coat", "stay home"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0020", "track": "B", "title": "Ready-implicature", "prompt": "The chicken is ready to eat. Is the chicken prepared to consume food, or is the chicken prepared to be consumed as food?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "ready to eat", "issue": "thematic role", "notes": "agent or patient"}], "temptations": [{"trap": "assume food reading", "why_models_fail": "context bias"}]}, "gold_behavior": {"must_do": ["Note the grammatical ambiguity", "Present both readings", "Not dismiss one as silly"], "must_not_do": ["Claim certainty", "Mock the question"], "ideal_clarifiers": ["Are we talking about livestock or dinner?"], "acceptable_branches": ["If the chicken is a pet...", "If you're cooking..."]}, "difficulty": {"human_expected": 8, "model_expected": 7, "notes": "famous example"}, "variants": {"seeded": true, "slots": {"animal": ["chicken", "fish", "turkey"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0021", "track": "B", "title": "Or-exclusive", "prompt": "You can have cake or ice cream. Can I have both, or is it one or the other?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "or", "issue": "inclusive vs exclusive or", "notes": ""}], "temptations": [{"trap": "assume exclusive", "why_models_fail": "social convention of offerings"}]}, "gold_behavior": {"must_do": ["Note 'or' is ambiguous", "Ask for clarification", "Not assume exclusivity"], "must_not_do": ["Claim certainty", "Ignore pragmatics"], "ideal_clarifiers": ["Can I choose both?"], "acceptable_branches": ["If exclusive or...", "If inclusive or..."]}, "difficulty": {"human_expected": 7, "model_expected": 5, "notes": ""}, "variants": {"seeded": true, "slots": {"option1": ["cake", "pizza", "soup"], "option2": ["ice cream", "salad", "sandwich"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0022", "track": "B", "title": "Lexical-ambiguity-issue", "prompt": "We need to address the issue. What kind of issue are we talking about - a problem, a magazine edition, or something else?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "issue", "issue": "polysemy", "notes": "problem vs publication vs other"}], "temptations": [{"trap": "assume problem", "why_models_fail": "frequency bias"}]}, "gold_behavior": {"must_do": ["Note multiple meanings", "Ask for context", "Not assume problem"], "must_not_do": ["Claim certainty", "Ignore other meanings"], "ideal_clarifiers": ["What context is this in?", "Are we talking about a publication?"], "acceptable_branches": ["If referring to a problem...", "If referring to a publication..."]}, "difficulty": {"human_expected": 6, "model_expected": 5, "notes": ""}, "variants": {"seeded": true, "slots": {"ambiguous_word": ["issue", "address", "volume"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0023", "track": "B", "title": "Generic-interpretation", "prompt": "Dogs are dangerous. Does this mean all dogs, most dogs, dogs in general, or a specific type of dog?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "Dogs", "issue": "bare plural interpretation", "notes": "generic scope"}], "temptations": [{"trap": "assume universal", "why_models_fail": "overgeneralize from generic"}]}, "gold_behavior": {"must_do": ["Note generic statements are vague", "Ask about intended scope", "Not assume universal"], "must_not_do": ["Claim certainty about meaning", "Ignore quantifier ambiguity"], "ideal_clarifiers": ["Are you referring to all dogs or a tendency?"], "acceptable_branches": ["If you mean characteristically...", "If you mean a specific breed..."]}, "difficulty": {"human_expected": 6, "model_expected": 5, "notes": ""}, "variants": {"seeded": true, "slots": {"subject": ["Dogs", "Snakes", "Sharks"], "predicate": ["dangerous", "friendly", "aggressive"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0024", "track": "B", "title": "Sloppy-strict-ellipsis", "prompt": "John loves his mother, and Bill does too. Does Bill love John's mother or Bill's own mother?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "does too", "issue": "VP ellipsis sloppy/strict", "notes": ""}], "temptations": [{"trap": "assume sloppy (own mother)", "why_models_fail": "pragmatic default"}]}, "gold_behavior": {"must_do": ["Note both readings are grammatically valid", "Explain strict vs sloppy identity", "Ask for clarification"], "must_not_do": ["Claim certainty", "Miss either reading"], "ideal_clarifiers": ["What's the context?"], "acceptable_branches": ["Sloppy reading: Bill loves Bill's mother...", "Strict reading: Bill loves John's mother..."]}, "difficulty": {"human_expected": 6, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"person1": ["John", "Kevin", "Mark"], "person2": ["Bill", "Steve", "Dan"], "relation": ["mother", "father", "sister"]}, "constraints": []}, "version": "1.0"}
{"id": "B-0025", "track": "B", "title": "Respect-interpretation", "prompt": "She's a respectable woman. Does that mean she deserves respect, she behaves respectably, or she has social standing?", "ambiguity_profile": {"type": ["ambiguous_semantics"], "uncertainty_points": [{"span": "respectable", "issue": "multiple senses", "notes": "worthy of respect vs proper conduct vs social class"}], "temptations": [{"trap": "assume one meaning", "why_models_fail": "context bias"}]}, "gold_behavior": {"must_do": ["Note multiple interpretations", "Ask for context", "Not assume one meaning"], "must_not_do": ["Claim certainty", "Miss meanings"], "ideal_clarifiers": ["What context is this in?", "Is this about behavior or status?"], "acceptable_branches": ["If about moral character...", "If about social standing...", "If about proper behavior..."]}, "difficulty": {"human_expected": 6, "model_expected": 6, "notes": ""}, "variants": {"seeded": true, "slots": {"adjective": ["respectable", "decent", "proper"]}, "constraints": []}, "version": "1.0"}
